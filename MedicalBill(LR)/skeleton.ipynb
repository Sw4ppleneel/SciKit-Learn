{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22726b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Download the dataset\n",
    "od.download('https://www.kaggle.com/jsphyg/weather-dataset-rattle-package')\n",
    "raw_df = pd.read_csv('weather-dataset-rattle-package/weatherAUS.csv')\n",
    "raw_df.dropna(subset=['RainToday', 'RainTomorrow'], inplace=True)\n",
    "\n",
    "# Create training, validation and test sets\n",
    "year = pd.to_datetime(raw_df.Date).dt.year\n",
    "train_df, val_df, test_df = raw_df[year < 2015], raw_df[year == 2015], raw_df[year > 2015]\n",
    "\n",
    "# Create inputs and targets\n",
    "input_cols = list(train_df.columns)[1:-1]\n",
    "target_col = 'RainTomorrow'\n",
    "train_inputs, train_targets = train_df[input_cols].copy(), train_df[target_col].copy()\n",
    "val_inputs, val_targets = val_df[input_cols].copy(), val_df[target_col].copy()\n",
    "test_inputs, test_targets = test_df[input_cols].copy(), test_df[target_col].copy()\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_cols = train_inputs.select_dtypes(include=np.number).columns.tolist()[:-1]\n",
    "categorical_cols = train_inputs.select_dtypes('object').columns.tolist()\n",
    "\n",
    "# Impute missing numerical values\n",
    "imputer = SimpleImputer(strategy = 'mean').fit(raw_df[numeric_cols])\n",
    "train_inputs[numeric_cols] = imputer.transform(train_inputs[numeric_cols])\n",
    "val_inputs[numeric_cols] = imputer.transform(val_inputs[numeric_cols])\n",
    "test_inputs[numeric_cols] = imputer.transform(test_inputs[numeric_cols])\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = MinMaxScaler().fit(raw_df[numeric_cols])\n",
    "train_inputs[numeric_cols] = scaler.transform(train_inputs[numeric_cols])\n",
    "val_inputs[numeric_cols] = scaler.transform(val_inputs[numeric_cols])\n",
    "test_inputs[numeric_cols] = scaler.transform(test_inputs[numeric_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore').fit(raw_df[categorical_cols])\n",
    "encoded_cols = list(encoder.get_feature_names(categorical_cols))\n",
    "train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
    "val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
    "test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
    "\n",
    "# Save processed data to disk\n",
    "train_inputs.to_parquet('train_inputs.parquet')\n",
    "val_inputs.to_parquet('val_inputs.parquet')\n",
    "test_inputs.to_parquet('test_inputs.parquet')\n",
    "pd.DataFrame(train_targets).to_parquet('train_targets.parquet')\n",
    "pd.DataFrame(val_targets).to_parquet('val_targets.parquet')\n",
    "pd.DataFrame(test_targets).to_parquet('test_targets.parquet')\n",
    "\n",
    "# Load processed data from disk\n",
    "train_inputs = pd.read_parquet('train_inputs.parquet')\n",
    "val_inputs = pd.read_parquet('val_inputs.parquet')\n",
    "test_inputs = pd.read_parquet('test_inputs.parquet')\n",
    "train_targets = pd.read_parquet('train_targets.parquet')[target_col]\n",
    "val_targets = pd.read_parquet('val_targets.parquet')[target_col]\n",
    "test_targets = pd.read_parquet('test_targets.parquet')[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a677118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ## Model Training and Evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Select the columns to be used for training/prediction\n",
    "X_train = train_inputs[numeric_cols + encoded_cols]\n",
    "X_val = val_inputs[numeric_cols + encoded_cols]\n",
    "X_test = test_inputs[numeric_cols + encoded_cols]\n",
    "\n",
    "# Create and train the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, train_targets)\n",
    "\n",
    "# Generate predictions and probabilities\n",
    "train_preds = model.predict(X_train)\n",
    "train_probs = model.predict_proba(X_train)\n",
    "accuracy_score(train_targets, train_preds)\n",
    "\n",
    "# Helper function to predict, compute accuracy & plot confustion matrix\n",
    "def predict_and_plot(inputs, targets, name=''):\n",
    "    preds = model.predict(inputs)\n",
    "    accuracy = accuracy_score(targets, preds)\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "    cf = confusion_matrix(targets, preds, normalize='true')\n",
    "    plt.figure()\n",
    "    sns.heatmap(cf, annot=True)\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Target')\n",
    "    plt.title('{} Confusion Matrix'.format(name));    \n",
    "    return preds\n",
    "\n",
    "# Evaluate on validation and test set\n",
    "val_preds = predict_and_plot(X_val, val_targets, 'Validation')\n",
    "test_preds = predict_and_plot(X_test, test_targets, 'Test')\n",
    "\n",
    "# Save the trained model & load it back\n",
    "aussie_rain = {'model': model, 'imputer': imputer, 'scaler': scaler, 'encoder': encoder,\n",
    "               'input_cols': input_cols, 'target_col': target_col, 'numeric_cols': numeric_cols,\n",
    "               'categorical_cols': categorical_cols, 'encoded_cols': encoded_cols}\n",
    "joblib.dump(aussie_rain, 'aussie_rain.joblib')\n",
    "aussie_rain2 = joblib.load('aussie_rain.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e760bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on single input\n",
    "\n",
    "\n",
    "\n",
    "def predict_input(single_input):\n",
    "    input_df = pd.DataFrame([single_input])\n",
    "    input_df[numeric_cols] = imputer.transform(input_df[numeric_cols])\n",
    "    input_df[numeric_cols] = scaler.transform(input_df[numeric_cols])\n",
    "    input_df[encoded_cols] = encoder.transform(input_df[categorical_cols])\n",
    "    X_input = input_df[numeric_cols + encoded_cols]\n",
    "    pred = model.predict(X_input)[0]\n",
    "    prob = model.predict_proba(X_input)[0][list(model.classes_).index(pred)]\n",
    "    return pred, prob\n",
    "\n",
    "new_input = {'Date': '2021-06-19',\n",
    "             'Location': 'Launceston',\n",
    "             'MinTemp': 23.2,\n",
    "             'MaxTemp': 33.2,\n",
    "             'Rainfall': 10.2,\n",
    "             'Evaporation': 4.2,\n",
    "             'Sunshine': np.nan,\n",
    "             'WindGustDir': 'NNW',\n",
    "             'WindGustSpeed': 52.0,\n",
    "             'WindDir9am': 'NW',\n",
    "             'WindDir3pm': 'NNE',\n",
    "             'WindSpeed9am': 13.0,\n",
    "             'WindSpeed3pm': 20.0,\n",
    "             'Humidity9am': 89.0,\n",
    "             'Humidity3pm': 58.0,\n",
    "             'Pressure9am': 1004.8,\n",
    "             'Pressure3pm': 1001.5,\n",
    "             'Cloud9am': 8.0,\n",
    "             'Cloud3pm': 5.0,\n",
    "             'Temp9am': 25.7,\n",
    "             'Temp3pm': 33.0,\n",
    "             'RainToday': 'Yes'}\n",
    "\n",
    "predict_input(new_input)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
